{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "* Student name: Miguel Santana\n",
    "* Student pace: Full Time\n",
    "* Scheduled project review date/time: 10/14/2020, 12-12:45pm\n",
    "* Instructor name: James Irving\n",
    "* Blog post URL: TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Methodology & Goal\n",
    "**A Portuguese financial institution provided data resulting from various direct telemarketing campaigns with the goal of predicting subscriber term deposits. The following will include an in depth analysis of the client, campaign, social, economic and additional features that lend to predicting whether a client will subscribe a term deposit. The analysis will culminate in actionable business recommendations that will drive the target variable.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Citation:\n",
    "\n",
    "[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n",
    "\n",
    "Available via:\n",
    "* UCI's machine learning repository http://archive.ics.uci.edu/ml/datasets/Bank+Marketing#\n",
    "\n",
    "* Kaggle https://www.kaggle.com/henriqueyamahata/bank-marketing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Modeling\n",
    "OSEMN Framework\n",
    "* Obtain\n",
    "* Scrub\n",
    "* Explore\n",
    "* Model\n",
    "* INterpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Project Libraries\n",
    "Importing Packages & Processing our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:34.662261Z",
     "start_time": "2020-10-13T19:17:33.365388Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Math, Visualizations, Cleaning and Analysis\n",
    "import pandas as pd # data cleaning and manipulation\n",
    "import numpy as np # numerical operations  \n",
    "import seaborn as sns # visualizations / plt.style.use('seaborn-poster') \n",
    "#sns.set(style='whitegrid')\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# pd.set_option('display.max_columns',0)\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Machine Learning / Reporting\n",
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:34.754497Z",
     "start_time": "2020-10-13T19:17:34.664066Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Key\n",
    "The dataset includes the following client, campaign, social, economic and other attributes:\n",
    "\n",
    "**Client Data**\n",
    "* Age\n",
    "* Job Type\n",
    "* Marital Status\n",
    "* Education \n",
    "* Default **(client credit in default)**\n",
    "* Housing **(client housing loan)**\n",
    "* Loan **(client personal loan)**\n",
    "\n",
    "**Current Campaign | Last Contact** \n",
    "* Contact Type\n",
    "* Month \n",
    "* Day of Week \n",
    "* Duration (in seconds)\n",
    "\n",
    "**Other Attributes:**\n",
    "* Campaign (number of contacts/this campaign)\n",
    "* Pdays (days since last contacted/previous campaign)\n",
    "* Previous (contacts performed before this campaign/this client)\n",
    "* Poutcome (previous campaign outcome)\n",
    "\n",
    "**Social & Economic Context Attributes**\n",
    "* Emp.var.rate (quarterly employment variation rate)\n",
    "* Cons.price.idx (monthly indicator - consumer price index)\n",
    "* Cons.conf.idx (monthly indicator - consumer confidence index)\n",
    "* Euribor3m (daily indicator - euribor 3 month rate)\n",
    "* Nr.employed (quarterly indicator - number of employees)\n",
    "\n",
    "**Output/Target**\n",
    "* y (has the client subscribed a term deposit?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:34.779134Z",
     "start_time": "2020-10-13T19:17:34.756543Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'y':'term_deposit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:34.807823Z",
     "start_time": "2020-10-13T19:17:34.781151Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:34.880610Z",
     "start_time": "2020-10-13T19:17:34.809185Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in df.columns: # preliminary view of value counts per column\n",
    "    try:\n",
    "        print(col, df[col].value_counts()[:5])\n",
    "    except:\n",
    "        print(col, df[col].value_counts())\n",
    "        # If there aren't 5+ unique values for a column the first print statement\n",
    "        # will throw an error for an invalid idx slice\n",
    "    print('\\n') # Break up the output between columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null & Unknown Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:34.970590Z",
     "start_time": "2020-10-13T19:17:34.882742Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Missing values : ', df.isnull().sum().values.sum()) # null values\n",
    "print('\\n')\n",
    "print('Unique values: \\n', df.nunique()) # unique values per column\n",
    "# df.isnull().values.any() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "There are no missing values in the dataset. There are a substantial amount of \"unknown\" values which will need to be addressed.  \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T01:25:12.865081Z",
     "start_time": "2020-10-02T01:25:12.863388Z"
    }
   },
   "source": [
    "## Addressing Unknown Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.026424Z",
     "start_time": "2020-10-13T19:17:34.971990Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Unknown Values Per Column')\n",
    "for col in df.columns: # preliminary view of value counts per column\n",
    "    try:\n",
    "        print(col, df[col].value_counts()['unknown'])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T16:55:49.050094Z",
     "start_time": "2020-10-05T16:55:49.046522Z"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "In order to narrow down my dataset I will drop the \"unknown\" values from each column except for 'default'. After processing both updates ('unknown' & outlier removal) I should maintain over 90% of my original dataset.\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.033234Z",
     "start_time": "2020-10-13T19:17:35.029352Z"
    }
   },
   "outputs": [],
   "source": [
    "orig_len = len(df)\n",
    "orig_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.038212Z",
     "start_time": "2020-10-13T19:17:35.035527Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping unknown variables from various columns\n",
    "def drop_unknown(df, col_name):\n",
    "    start_len = len(df)\n",
    "    new_df = df.loc[(df[col_name] != 'unknown')]\n",
    "    print(f'There were {start_len - len(new_df)} unknown values removed from {col_name}')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.050092Z",
     "start_time": "2020-10-13T19:17:35.039687Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_job = drop_unknown(df, 'job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.060937Z",
     "start_time": "2020-10-13T19:17:35.051793Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_marital = drop_unknown(remove_job, 'marital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.072360Z",
     "start_time": "2020-10-13T19:17:35.062403Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_education = drop_unknown(remove_marital, 'education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.084746Z",
     "start_time": "2020-10-13T19:17:35.074118Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_housing = drop_unknown(remove_education, 'housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.094814Z",
     "start_time": "2020-10-13T19:17:35.086300Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_loan = drop_unknown(remove_housing, 'loan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.099654Z",
     "start_time": "2020-10-13T19:17:35.096281Z"
    }
   },
   "outputs": [],
   "source": [
    "df = remove_loan\n",
    "print(f'There were {orig_len - len(remove_loan)} unknown values removed from the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier removal will be centered on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.105184Z",
     "start_time": "2020-10-13T19:17:35.101060Z"
    }
   },
   "outputs": [],
   "source": [
    "# IQR Outlier Removal Function\n",
    "def iqr_outlier_rem(df, col_name):\n",
    "    start_len = len(df)\n",
    "    Q1 = df[col_name].quantile(0.25)\n",
    "    Q3 = df[col_name].quantile(0.75)\n",
    "    IQR = Q3-Q1 # Finding interquartile range\n",
    "    lower_threshold  = Q1-1.5*IQR\n",
    "    upper_threshold = Q3+1.5*IQR\n",
    "    new_df = df.loc[(df[col_name] > lower_threshold) & (df[col_name] < upper_threshold)]\n",
    "    print(f'There were {start_len - len(new_df)} outliers removed from {col_name}')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.119641Z",
     "start_time": "2020-10-13T19:17:35.106786Z"
    }
   },
   "outputs": [],
   "source": [
    "df = iqr_outlier_rem(df, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.130353Z",
     "start_time": "2020-10-13T19:17:35.121173Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.134558Z",
     "start_time": "2020-10-13T19:17:35.131922Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'The new dataframe represents {(len(df)/orig_len) * 100} percent of the original dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The dataset now represents clients between the ages of 17 and 69 with a specific job status, marital status, education level and housing or personal loan status per bank records. \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:35.138540Z",
     "start_time": "2020-10-13T19:17:35.136049Z"
    }
   },
   "outputs": [],
   "source": [
    "# ['default', 'housing', 'loan', 'term_deposit'] binary columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Last Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:36.188428Z",
     "start_time": "2020-10-13T19:17:35.139911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x='term_deposit',data=df)\n",
    "ax.set(xlabel='Subscribed Term Deposit', ylabel='Count', title='Term Deposit')\n",
    "for a in ax.patches:\n",
    "        ax.annotate('{:.2f}%'.format((a.get_height()/df.shape[0])*100), (a.get_x()+0.3, a.get_height()))\n",
    "\n",
    "axb = df.groupby(['month', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "axb.set(xlabel='Month', ylabel='Term Deposit Count', title='Term Deposit X Contact Month')\n",
    "for ab in axb.patches:\n",
    "    axb.text(ab.get_x()+0.05, ab.get_height()+20,str(ab.get_height()))\n",
    "\n",
    "ax2 = df.groupby(['day_of_week', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax2.set(xlabel='Day', ylabel='Term Deposit Count', title='Term Deposit X Contact Day of Week')\n",
    "for b in ax2.patches:\n",
    "    ax2.text(b.get_x()+0.05, b.get_height()+20,str(b.get_height()))\n",
    "\n",
    "ax3 = df.groupby(['contact', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax3.set(xlabel='Contact Type', ylabel='Term Deposit Count', title='Term Deposit X Contact Type')\n",
    "for c in ax3.patches:\n",
    "    ax3.text(c.get_x()+0.05, c.get_height()+20,str(c.get_height()))\n",
    "\n",
    "    \n",
    "# plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Observations\n",
    "* There is a wide distribution of data when considering term deposits per month. The months with the most even distribution of yes/no are March, September, October and December.\n",
    "* There is no distinguishable difference in term deposits per day of the week. \n",
    "* The data illustrates higher odds of a subscriber term deposit when clients are reached via cell phone versus telephone. This may be due to changes in technology as less consumers maintain an active land line phone at home. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Age, Job, Education & Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:36.209163Z",
     "start_time": "2020-10-13T19:17:36.190674Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fresh = df.copy()\n",
    "df_fresh['age_bin'] = df_fresh['age'].apply(lambda x: '[17, 25)' if x < 25 \n",
    "                                else '[25, 35)' if x < 35 \n",
    "                                else '[35, 45)' if x < 45\n",
    "                                else '[55, 65)' if x < 65\n",
    "                                else '65+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:37.383424Z",
     "start_time": "2020-10-13T19:17:36.214515Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "\n",
    "ax = df_fresh.groupby(['age_bin', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax.set(xlabel='Age Group', ylabel='Term Deposit Count', title='Term Deposit X Age')\n",
    "for a in ax.patches:\n",
    "    ax.text(a.get_x()+0.05, a.get_height()+20,str(a.get_height()))\n",
    "    \n",
    "ax2 = df.groupby(['job', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax2.set(xlabel='Job Type', ylabel='Term Deposit Count', title='Term Deposit X Job Type')\n",
    "for b in ax2.patches:\n",
    "    ax2.text(b.get_x()+0.05, b.get_height()+20,str(b.get_height()))\n",
    "\n",
    "ax3 = df.groupby(['education', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax3.set(xlabel='Education Level', ylabel='Term Deposit Count', title='Term Deposit X Education Completed')\n",
    "for c in ax3.patches:\n",
    "    ax3.text(c.get_x()+0.05, c.get_height()+20,str(c.get_height()))\n",
    "\n",
    "ax4 = df.groupby(['marital', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax4.set(xlabel='Marital Status', ylabel='Term Deposit Count', title='Term Deposit X Marital Status')\n",
    "for d in ax4.patches:\n",
    "    ax4.text(d.get_x()+0.05, d.get_height()+20,str(d.get_height()))\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Observations\n",
    "* The data is unbalanced with just under 11 percent of clients subscribing for a term deposit.\n",
    "* Some client jobs hold a closer no/yes ratio regarding term deposits. The four jobs with the largest variation are: admin, blue-collar, services and technician.  \n",
    "* The gap between no and yes variables appears to grow the more education a client has completed. Professional course and basic 6 year are the exception. \n",
    "* The majority of the dataset is represented by married couples with the greatest no/yes ratio existing in the \"divorced\" category.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:37.404132Z",
     "start_time": "2020-10-13T19:17:37.387276Z"
    }
   },
   "outputs": [],
   "source": [
    "dfclean = df.copy() # clean copy for final model analysis\n",
    "yesdf = df[df['term_deposit'] == 'yes']\n",
    "nodf = df[df['term_deposit'] == 'no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The dataset will be separated in order to show features that are representative of a \"yes\" in our target variable.\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notable Data Columns / Feature Conversions \n",
    "* Education - variables will be converted to numerical\n",
    "* Duration - a duration of zero directly ties to the target 'no' (remove before modeling)\n",
    "* Pdays - a value of 999 means the customer has not been contacted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:37.433436Z",
     "start_time": "2020-10-13T19:17:37.412703Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['education'].replace({'illiterate': 0, \n",
    "                         'basic.4y': 4, 'basic.6y': 6, \n",
    "                         'basic.9y': 9, 'high.school': 12, \n",
    "                         'professional.course': 14, \n",
    "                         'university.degree': 16}, inplace=True)\n",
    "\n",
    "# df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:37.437007Z",
     "start_time": "2020-10-13T19:17:37.435076Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop duration per dataset guidelines / drop columns with negative values\n",
    "#df = df.drop(['duration', 'emp.var.rate', 'cons.conf.idx'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:37.448675Z",
     "start_time": "2020-10-13T19:17:37.438357Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop duration per dataset guidelines\n",
    "df = df.drop(['duration'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.103911Z",
     "start_time": "2020-10-13T19:17:37.450125Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = df.corr() # analyzing correlation\n",
    "# corr\n",
    "fig, ax = plt.subplots(figsize=(18,26))\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "sns.heatmap(corr, mask=mask, square=True, annot=True, cmap=\"YlGnBu\")\n",
    "#xticklabels=labels, yticklabels=labels)\n",
    "#plt.xticks(rotation=-45, fontsize=16)\n",
    "ax.patch.set_edgecolor('black')  \n",
    "ax.patch.set_linewidth('1')\n",
    "ax.set_title(\"Correlation & Heat Map\", fontsize=15, fontfamily=\"serif\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.111335Z",
     "start_time": "2020-10-13T19:17:38.105351Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping features to address multicollinearity \n",
    "df = df.drop(['emp.var.rate', 'euribor3m'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.116430Z",
     "start_time": "2020-10-13T19:17:38.112810Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning Column Names\n",
    "subs = [(' ', '_'),('.0',''),('.',''),('-','_')]\n",
    "\n",
    "def col_formatting(col):\n",
    "    for old, new in subs:\n",
    "        col = col.replace(old,new)\n",
    "    return col\n",
    "\n",
    "df.columns = [col_formatting(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.151255Z",
     "start_time": "2020-10-13T19:17:38.117866Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.190154Z",
     "start_time": "2020-10-13T19:17:38.152728Z"
    }
   },
   "outputs": [],
   "source": [
    "# Converting uint8 datatypes back to categorical variables \n",
    "for cat_cols in df.iloc[:,8:].columns:\n",
    "         df[cat_cols] = df[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.213499Z",
     "start_time": "2020-10-13T19:17:38.191562Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.220663Z",
     "start_time": "2020-10-13T19:17:38.215219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Identify X, y\n",
    "y = df['term_deposit_yes']\n",
    "X = df.drop(['term_deposit_yes'], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.393378Z",
     "start_time": "2020-10-13T19:17:38.222055Z"
    }
   },
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "scaler = StandardScaler() # transform \"X\" features\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.415642Z",
     "start_time": "2020-10-13T19:17:38.395264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test/Train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.495249Z",
     "start_time": "2020-10-13T19:17:38.417474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:38.502687Z",
     "start_time": "2020-10-13T19:17:38.497049Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_visuals (model, X_test, y_test):\n",
    "    '''Plots the confusion matrix and ROC-AUC plot'''\n",
    "    fig, axes = plt.subplots(figsize = (12, 6), ncols = 2)  # confusion matrix\n",
    "    metrics.plot_confusion_matrix(model, X_test, y_test, normalize = 'true', \n",
    "                          cmap = 'Blues', ax = axes[0])\n",
    "    axes[0].set_title('Confusion Matrix');\n",
    "    # ROC-AUC Curve\n",
    "    roc_auc = metrics.plot_roc_curve(model, X_test, y_test,ax=axes[1])\n",
    "    axes[1].plot([0,1],[0,1],ls=':')\n",
    "    axes[1].set_title('ROC-AUC Plot')\n",
    "    axes[1].grid()\n",
    "    axes[1].legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:39.168038Z",
     "start_time": "2020-10-13T19:17:38.504217Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# Observe time lapse\n",
    "logreg_clf = LogisticRegression()\n",
    "logreg_model = logreg_clf.fit(X_train, y_train)\n",
    "logreg_prediction = logreg_clf.predict(X_test)\n",
    "\n",
    "lrs = round(accuracy_score(logreg_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', lrs)\n",
    "print('\\n')\n",
    "print(classification_report(logreg_prediction, y_test), '\\n\\n')\n",
    "model_visuals (logreg_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:41.873931Z",
     "start_time": "2020-10-13T19:17:39.174208Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "ranfor_clf = RandomForestClassifier() # random forest \n",
    "ranfor_model = ranfor_clf.fit(X_train, y_train)\n",
    "ranfor_prediction = ranfor_clf.predict(X_test)\n",
    "\n",
    "random_forest_score = round(accuracy_score(ranfor_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', random_forest_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(ranfor_prediction, y_test), '\\n\\n')\n",
    "model_visuals (ranfor_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:17:57.769313Z",
     "start_time": "2020-10-13T19:17:41.880988Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "svm_clf = SVC()\n",
    "svm_model = svm_clf.fit(X_train, y_train)\n",
    "svm_prediction = svm_clf.predict(X_test)\n",
    "\n",
    "svm_score = round(accuracy_score(svm_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', svm_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(svm_prediction, y_test), '\\n\\n')\n",
    "model_visuals (svm_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:18:02.346812Z",
     "start_time": "2020-10-13T19:17:57.774903Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_model = knn_clf.fit(X_train, y_train)\n",
    "knn_prediction = knn_clf.predict(X_test)\n",
    "\n",
    "knn_score = round(accuracy_score(knn_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', knn_score)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print(classification_report(knn_prediction, y_test), '\\n\\n')\n",
    "model_visuals (knn_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:18:02.889773Z",
     "start_time": "2020-10-13T19:18:02.353726Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "gaussian_clf = GaussianNB() #gaissian naive bayes\n",
    "gaussian_model = gaussian_clf.fit(X_train, y_train)\n",
    "gaussian_prediction = gaussian_clf.predict(X_test)\n",
    "\n",
    "gaussian_score = round(accuracy_score(gaussian_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', gaussian_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(gaussian_prediction, y_test), '\\n\\n\\n')\n",
    "model_visuals (gaussian_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:18:03.466058Z",
     "start_time": "2020-10-13T19:18:02.896492Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "dectree_clf = DecisionTreeClassifier() # Decision Tree \n",
    "dectree_model = dectree_clf.fit(X_train, y_train)\n",
    "dectree_prediction = dectree_clf.predict(X_test)\n",
    "\n",
    "decision_tree_score = round(accuracy_score(dectree_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', decision_tree_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(dectree_prediction, y_test), '\\n\\n')\n",
    "model_visuals (dectree_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:18:06.116941Z",
     "start_time": "2020-10-13T19:18:03.472599Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_model = gb_clf.fit(X_train, y_train)\n",
    "gb_prediction = gb_clf.predict(X_test)\n",
    "\n",
    "gbclf_score = round(accuracy_score(gb_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', gbclf_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(gb_prediction, y_test), '\\n\\n')\n",
    "model_visuals (gb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:18:10.337579Z",
     "start_time": "2020-10-13T19:18:06.123580Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "adabst_clf = AdaBoostClassifier()\n",
    "adabst_model = adabst_clf.fit(X_train, y_train)\n",
    "adabst_prediction = adabst_clf.predict(X_test)\n",
    "\n",
    "adabst_score = round(accuracy_score(adabst_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', adabst_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(adabst_prediction, y_test), '\\n\\n')\n",
    "model_visuals (adabst_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T19:18:10.355563Z",
     "start_time": "2020-10-13T19:18:10.345213Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# results dataframe\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression',\n",
    "              'KNN', \n",
    "              'Random Forest', \n",
    "              'Gaussian Naive Bayes',\n",
    "              'Support Vector Machine (SVC)', \n",
    "              'Decision Tree', \n",
    "              'AdaBoostClassifier', \n",
    "              'GradientBoostingClassifier',\n",
    "             ],\n",
    "    'Score': [lrs, \n",
    "              knn_score, \n",
    "              random_forest_score, \n",
    "              gaussian_score,\n",
    "              svm_score, \n",
    "              decision_tree_score,\n",
    "              adabst_score, \n",
    "              gbclf_score, \n",
    "             ]})\n",
    "\n",
    "models.sort_values(by='Score', ascending=False) #sorting by score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "It looks like Gradient Boosting Classifier is the most accurate with Ada Boost Classifier coming in at second place (close second). Decision Tree is coming in at last place approximate 7 percentage points lower than the most accurate model. \n",
    "\n",
    "\n",
    "It is worth noting that the unbalanced target leads me to consider models based on the precision, recall and F1 score of the \"1\" variable (target \"yes\"). Fortunately, Gradient Boosting Classifier and Ada Boost Classifier performed well with recall scores over 0.65 and F1 scores over 0.32. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier with GridSearchCV\n",
    "Let's see if we can improve our results at all using GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:02:30.247149Z",
     "start_time": "2020-10-13T20:00:23.438470Z"
    }
   },
   "source": [
    "``` Python\n",
    "# Grid Search Parameters\n",
    "learn_rates = [0.05, 0.1]\n",
    "max_depths = [2, 3]\n",
    "min_samples_leaf = [5,10]\n",
    "min_samples_split = [5,10]\n",
    "\n",
    "param_grid = {'learning_rate': learn_rates,\n",
    "              'max_depth': max_depths,\n",
    "              'min_samples_leaf': min_samples_leaf,\n",
    "              'min_samples_split': min_samples_split}\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(), \n",
    "                           param_grid, cv=5, return_train_score=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
    "             param_grid={'learning_rate': [0.05, 0.1], 'max_depth': [2, 3],\n",
    "                         'min_samples_leaf': [5, 10],\n",
    "                         'min_samples_split': [5, 10]},\n",
    "             return_train_score=True)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:02:35.582611Z",
     "start_time": "2020-10-13T20:02:35.490171Z"
    }
   },
   "source": [
    "``` Python\n",
    "print(grid_search.score(X_train, y_train))\n",
    "print(grid_search.best_params_)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:04:23.782573Z",
     "start_time": "2020-10-13T20:04:23.778743Z"
    }
   },
   "source": [
    "``` \n",
    "0.9074869490517412\n",
    "{'learning_rate': 0.1, 'max_depth': 3, 'min_samples_leaf': 5, 'min_samples_split': 5}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Gridsearch CV did not raise the accuracy of the model. Let's see if we can improve the accuracy by addressing our class imbalance problem.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:09:14.899691Z",
     "start_time": "2020-10-13T20:09:14.767059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualizing churn\n",
    "plt.bar(['No Term Deposit', 'Term Deposit'], df.term_deposit_yes.value_counts().values, facecolor = 'blue',  linewidth=0.5)\n",
    "plt.title('Target Variable (Subscribed Term Deposits)', fontsize=16)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Total Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:17:31.625260Z",
     "start_time": "2020-10-05T22:17:31.621146Z"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The graph above highlights that there is a a pretty high level of imbalance. We can remedy this using SMOTE.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:09:34.538169Z",
     "start_time": "2020-10-13T20:09:34.531847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "y = df['term_deposit_yes']\n",
    "X = df.drop(['term_deposit_yes'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:09:38.810626Z",
     "start_time": "2020-10-13T20:09:38.643564Z"
    }
   },
   "outputs": [],
   "source": [
    "X_scaled = scaler.fit_transform(X) #scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:09:40.958437Z",
     "start_time": "2020-10-13T20:09:40.944980Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0) #test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:15:43.186335Z",
     "start_time": "2020-10-13T20:15:41.946604Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE #import smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:15:57.699100Z",
     "start_time": "2020-10-13T20:15:57.696448Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=0) #random state 0 for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:16:01.071878Z",
     "start_time": "2020-10-13T20:16:00.703818Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train) #fitting smote to our train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:16:03.257802Z",
     "start_time": "2020-10-13T20:16:03.134392Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Updated bar graph to display amount of failed vs. successful campaigns post-SMOTE\n",
    "plt.bar(['Customer Retention', 'Customer Churn'], [sum(y_res), len(y_res)-sum(y_res)], facecolor = 'green',  linewidth=0.5)\n",
    "plt.title('Post-SMOTE Target Variable (Success)\\n', fontsize=16)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of Campaigns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "It looks like our classes are balanced now. Let's proceed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_model = gb_clf.fit(X_train, y_train)\n",
    "gb_prediction = gb_clf.predict(X_test)\n",
    "\n",
    "gbclf_score = round(accuracy_score(gb_prediction, y_test)*100,2)\n",
    "print('Accuracy Percentage', gbclf_score)\n",
    "print('\\n')\n",
    "\n",
    "print(classification_report(gb_prediction, y_test), '\\n\\n')\n",
    "model_visuals (gb_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:23:09.027985Z",
     "start_time": "2020-10-13T20:23:09.024133Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Top 2 + 2 to save time\n",
    "adabst_clf = AdaBoostClassifier()\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "ranfor_clf = RandomForestClassifier()\n",
    "dectree_clf = DecisionTreeClassifier()\n",
    "\n",
    "classifiers = [adabst_clf, gb_clf, ranfor_clf, dectree_clf] # Classifiers\n",
    "classifiers_names = ['AdaBoost', 'Gradient Boost', 'Random Forest', 'Decision Tree'] # respective names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:23:28.938948Z",
     "start_time": "2020-10-13T20:23:15.761324Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# iterating through classifiers and appending accuracy to list of scores\n",
    "scores = []\n",
    "for i in range(len(classifiers)):\n",
    "    classifiers[i].fit(X_res, y_res)\n",
    "    scores.append(round(classifiers[i].score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:24:16.871494Z",
     "start_time": "2020-10-13T20:24:16.862197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataframe to compare results\n",
    "dfsmote = pd.DataFrame({'Model': classifiers_names, 'Score': scores})\n",
    "\n",
    "dfsmote.sort_values(by='Score', ascending=False) # sorting models by score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The models performed worse than they did initially. SMOTE did not significantly impact model performance. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance of Top Classifiers\n",
    "\n",
    "Now that we know which classifiers have the most accuracy with our data, let's compare which features were the most important in the top two models: **Gradient Boosting Classifier and Adaboost.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:30:03.647644Z",
     "start_time": "2020-10-13T20:30:03.633891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "gb_feature = pd.DataFrame({'Importance': gb_model.feature_importances_, 'Column': X.columns})\n",
    "gb_feature = gb_feature.sort_values(by='Importance', ascending=False) \n",
    "print('Catboost Top 25 Features')\n",
    "gb_feature[:25] # top 25 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:31:30.389908Z",
     "start_time": "2020-10-13T20:31:30.050010Z"
    }
   },
   "outputs": [],
   "source": [
    "gb_feature = gb_feature[:25] # top 25 features\n",
    "gb_feature.plot(kind='barh', x='Column', y='Importance', figsize=(20, 10), cmap = 'coolwarm')\n",
    "plt.title('Gradient Boosting Feature Importance \\n', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:34:22.590292Z",
     "start_time": "2020-10-13T20:34:22.577052Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "ada_feature = pd.DataFrame({'Importance': adabst_model.feature_importances_, 'Column': X.columns})\n",
    "ada_feature = ada_feature.sort_values(by='Importance', ascending=False) \n",
    "print('Adaboost Top 25 Features')\n",
    "ada_feature[:25] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:34:58.083604Z",
     "start_time": "2020-10-13T20:34:57.748626Z"
    }
   },
   "outputs": [],
   "source": [
    "ada_feature = ada_feature[:25] # top 25 features\n",
    "ada_feature.plot(kind='barh', x='Column', y='Importance', figsize=(20, 10), cmap = 'coolwarm')\n",
    "plt.title('Adaboost Feature Importance \\n', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:35:43.968526Z",
     "start_time": "2020-10-13T20:35:43.965187Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating lists / top 25 features in each classifier \n",
    "gb = gb_feature.Column.unique() \n",
    "ada = ada_feature.Column.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:35:55.655380Z",
     "start_time": "2020-10-13T20:35:55.651520Z"
    }
   },
   "outputs": [],
   "source": [
    "set(gb) & set(ada) # items appearing in both lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "There are 19 total items that appear in both classifier feature lists. \n",
    "\n",
    "Top rated features in both lists include:\n",
    "* **Number of employees | quarterly indicator (nremployed)**\n",
    "* **Age**\n",
    "* **Campaign | (number of contacts / this campaign)**\n",
    "* **Consumer Confidence Index | Cons.conf.idx (monthly indicator)**\n",
    "* **Days since last campaign contact | Pdays**\n",
    "* **Contact Type Telephone**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:49:16.803603Z",
     "start_time": "2020-10-13T20:49:16.801340Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# yesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:50:36.607322Z",
     "start_time": "2020-10-13T20:50:36.281895Z"
    }
   },
   "outputs": [],
   "source": [
    "number_employees = yesdf['nr.employed'].value_counts()\n",
    "df_number_employees = pd.DataFrame(number_employees)\n",
    "\n",
    "x_counts = df_number_employees['nr.employed'].index\n",
    "y_counts = df_number_employees['nr.employed']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 10)\n",
    "graph_number_employees = sns.barplot(x=x_counts, y=y_counts, data=df_number_employees, palette='winter_r')\n",
    "plt.title('Subscriber Term Deposits X Number of Employees (Quarterly)', fontdict={'fontsize': 16})\n",
    "plt.ylabel('Number of Term Deposits', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Number of Employees (Quarterly)', fontdict={'fontsize': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:50:46.502379Z",
     "start_time": "2020-10-13T20:50:45.537735Z"
    }
   },
   "outputs": [],
   "source": [
    "age = yesdf['age'].value_counts()\n",
    "df_age = pd.DataFrame(age)\n",
    "\n",
    "x_counts = df_age['age'].index\n",
    "y_counts = df_age['age']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 10)\n",
    "graph_df_age = sns.barplot(x=x_counts, y=y_counts, data=df_age, palette='winter_r')\n",
    "plt.title('Subscriber Term Deposits X Age', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Age', fontdict={'fontsize': 16})\n",
    "plt.ylabel('Number of Term Deposits', fontdict={'fontsize': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:52:53.690329Z",
     "start_time": "2020-10-13T20:52:53.289210Z"
    }
   },
   "outputs": [],
   "source": [
    "conf_idx = yesdf['cons.conf.idx'].value_counts()\n",
    "df_conf_idx = pd.DataFrame(conf_idx)\n",
    "\n",
    "x_counts = df_conf_idx['cons.conf.idx'].index\n",
    "y_counts = df_conf_idx['cons.conf.idx']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(24, 16)\n",
    "graph_conf_idx = sns.barplot(x=x_counts, y=y_counts, data=df_conf_idx, palette='winter_r')\n",
    "for item in graph_conf_idx.get_xticklabels():\n",
    "    item.set_rotation(90)\n",
    "plt.title('Subscriber Term Deposits X Consumer Confidence Index', fontdict={'fontsize': 16})\n",
    "plt.ylabel('Number of Term Deposits', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Consumer Confidence Index', fontdict={'fontsize': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:58:45.463031Z",
     "start_time": "2020-10-13T20:58:45.164521Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "campaign = yesdf['campaign'].value_counts()\n",
    "df_campaign = pd.DataFrame(campaign)\n",
    "\n",
    "x_counts = df_campaign['campaign'].index\n",
    "y_counts = df_campaign['campaign']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 10)\n",
    "graph_df_campaign = sns.barplot(x=x_counts, y=y_counts, data=df_campaign, palette='winter_r')\n",
    "plt.title('Subscriber Term Deposits X Current Campaign Contacts', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Number of Contacts this Campaign', fontdict={'fontsize': 16})\n",
    "plt.ylabel('Number of Term Deposits', fontdict={'fontsize': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:01:19.087517Z",
     "start_time": "2020-10-13T21:01:18.744422Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdays = yesdf['pdays'].value_counts()\n",
    "df_pdays = pd.DataFrame(pdays)\n",
    "\n",
    "x_counts = df_pdays['pdays'].index\n",
    "y_counts = df_pdays['pdays']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 10)\n",
    "graph_df_pdays = sns.barplot(x=x_counts, y=y_counts, data=df_pdays, palette='winter_r')\n",
    "plt.title('Subscriber Term Deposits X Last Contact', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Days Since Last Contact', fontdict={'fontsize': 16})\n",
    "plt.ylabel('Number of Term Deposits', fontdict={'fontsize': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T21:03:38.606197Z",
     "start_time": "2020-10-13T21:03:38.424924Z"
    }
   },
   "outputs": [],
   "source": [
    "contact = yesdf['contact'].value_counts()\n",
    "df_contact = pd.DataFrame(contact)\n",
    "\n",
    "x_counts = df_contact['contact'].index\n",
    "y_counts = df_contact['contact']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18, 10)\n",
    "graph_df_contact = sns.barplot(x=x_counts, y=y_counts, data=df_contact, palette='winter_r')\n",
    "plt.title('Subscriber Term Deposits X contact type', fontdict={'fontsize': 16})\n",
    "plt.xlabel('Days Since Last Contact', fontdict={'fontsize': 16})\n",
    "plt.ylabel('Number of Term Deposits', fontdict={'fontsize': 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-13T20:51:13.559288Z",
     "start_time": "2020-10-13T20:51:13.555379Z"
    }
   },
   "outputs": [],
   "source": [
    "yesdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion Business Insights and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset and given business insights relay specifically to a client base that cites their specific job type, marital status and education level. Additionally, the models and features reflect a client that is between 17-69 years of age. \n",
    "\n",
    "**Subscriber term deposits are highest when the number of quarterly employees are at least 5099 but not over 5228. In addition, consumer price index should be between 92.89 and 93.08. Lastly, clients between the ages of 30-40 are the most likely to subscribe term deposits.**\n",
    "\n",
    "Future work: In order to more accurately define the boundaries of our features it is important to understand what customs and cultural influences are tied to this dataset (Portuguese banking info). For example: knowing the average level of education, the geographic locations of client residences and information on financial markets in this region may alter the way we perceive each of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
