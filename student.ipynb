{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "* Student name: Miguel Santana\n",
    "* Student pace: Full Time\n",
    "* Scheduled project review date/time: 10/14/2020, 12-12:45pm\n",
    "* Instructor name: James Irving\n",
    "* Blog post URL: TBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Methodology & Goal\n",
    "The following dataset was retrieved from Kaggle. A Portuguese banking institution provided data regarding a direct marketing campaign with the goal of predicting subscriber term deposits. The following will include an in depth analysis of the client, campaign, social, economic and additional features that lend to predicting whether a client will subscribe a term deposit. The analysis culminate in business recommendations that will drive our target variable.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information was found on kaggle at: https://www.kaggle.com/henriqueyamahata/bank-marketing\n",
    "\n",
    "Dataset originally from: http://archive.ics.uci.edu/ml/datasets/Bank+Marketing#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis and Modeling\n",
    "OSEMN Framework\n",
    "* Obtain\n",
    "* Scrub\n",
    "* Explore\n",
    "* Model\n",
    "* INterpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Project Libraries\n",
    "Importing Packages & Processing our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.078670Z",
     "start_time": "2020-10-06T01:56:30.401535Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Math, Visualizations, Cleaning and Analysis\n",
    "import pandas as pd # data cleaning and manipulation\n",
    "import numpy as np # numerical operations  \n",
    "import seaborn as sns # visualizations / plt.style.use('seaborn-poster') \n",
    "#sns.set(style='whitegrid')\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# pd.set_option('display.max_columns',0)\n",
    "# pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.180329Z",
     "start_time": "2020-10-06T01:56:31.080635Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('bank-additional-full.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Key\n",
    "The Kaggle dataset lists the following bank client attributes:\n",
    "\n",
    "**Client Data**\n",
    "* Age\n",
    "* Job Type\n",
    "* Marital Status\n",
    "* Education \n",
    "* Default **(client credit in default)**\n",
    "* Housing **(client housing loan)**\n",
    "* Loan **(client personal loan)**\n",
    "\n",
    "**Current Campaign | Last Contact** \n",
    "* Contact Type\n",
    "* Month \n",
    "* Day of Week \n",
    "* Duration (in seconds)\n",
    "\n",
    "**Other Attributes:**\n",
    "* Campaign (number of contacts/this campaign)\n",
    "* Pdays (days since last contacted/previous campaign)\n",
    "* Previous (contacts performed before this campaign/this client)\n",
    "* Poutcome (previous campaign outcome)\n",
    "\n",
    "**Social & Economic Context Attributes**\n",
    "* Emp.var.rate (quarterly employment variation rate)\n",
    "* Cons.price.idx (monthly indicator - consumer price index)\n",
    "* Cons.conf.idx (monthly indicator - consumer confidence index)\n",
    "* Euribor3m (daily indicator - euribor 3 month rate)\n",
    "* Nr.employed (quarterly indicator - number of employees)\n",
    "\n",
    "**Output/Target**\n",
    "* y (has the client subscribed a term deposit?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.195540Z",
     "start_time": "2020-10-06T01:56:31.182482Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'y':'term_deposit'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.223218Z",
     "start_time": "2020-10-06T01:56:31.197391Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.289328Z",
     "start_time": "2020-10-06T01:56:31.224771Z"
    }
   },
   "outputs": [],
   "source": [
    "for col in df.columns: # preliminary view of value counts per column\n",
    "    try:\n",
    "        print(col, df[col].value_counts()[:5])\n",
    "    except:\n",
    "        print(col, df[col].value_counts())\n",
    "        # If there aren't 5+ unique values for a column the first print statement\n",
    "        # will throw an error for an invalid idx slice\n",
    "    print('\\n') # Break up the output between columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.308442Z",
     "start_time": "2020-10-06T01:56:31.291158Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.isnull().sum()\n",
    "df.isnull().values.any() # Checking for nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "There are no missing values in the dataset. There are a substantial amount of \"unknown\" values which will need to be addressed.  \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T01:25:12.865081Z",
     "start_time": "2020-10-02T01:25:12.863388Z"
    }
   },
   "source": [
    "## Addressing Unknown Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.312976Z",
     "start_time": "2020-10-06T01:56:31.309924Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "# df['term_deposit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unknown Values Per Column:\n",
    "   \n",
    "   job type: 330 \n",
    "   \n",
    "   marital status: 80\n",
    "   \n",
    "   education: 1731\n",
    "   \n",
    "   default (client credit in default): 8597\n",
    "   \n",
    "   housing (client housing loan): 990\n",
    "   \n",
    "   loan (client personal loan): 990\n",
    "   \n",
    "Total: 12718 or 30.88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T16:55:49.050094Z",
     "start_time": "2020-10-05T16:55:49.046522Z"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "In order to narrow down my dataset I will drop the \"unknown\" values from the job, marital and education columns. \n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.318227Z",
     "start_time": "2020-10-06T01:56:31.315445Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping unknown variables from 3 columns\n",
    "def dr_unknown(df, col_name):\n",
    "    start_len = len(df)\n",
    "    new_df = df.loc[(df[col_name] != 'unknown')]\n",
    "    print(f'There were {start_len - len(new_df)} unknown values removed from {col_name}')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.330883Z",
     "start_time": "2020-10-06T01:56:31.320106Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_job = dr_unknown(df, 'job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.343062Z",
     "start_time": "2020-10-06T01:56:31.332377Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_marital = dr_unknown(remove_job, 'marital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.354750Z",
     "start_time": "2020-10-06T01:56:31.344635Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_education = dr_unknown(remove_marital, 'education')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.361199Z",
     "start_time": "2020-10-06T01:56:31.356396Z"
    }
   },
   "outputs": [],
   "source": [
    "df = remove_education\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier removal will be centered on age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.366330Z",
     "start_time": "2020-10-06T01:56:31.362633Z"
    }
   },
   "outputs": [],
   "source": [
    "# IQR Outlier Removal Function\n",
    "def iqr_outlier_rem(df, col_name):\n",
    "    start_len = len(df)\n",
    "    Q1 = df[col_name].quantile(0.25)\n",
    "    Q3 = df[col_name].quantile(0.75)\n",
    "    IQR = Q3-Q1 # Finding interquartile range\n",
    "    lower_threshold  = Q1-1.5*IQR\n",
    "    upper_threshold = Q3+1.5*IQR\n",
    "    new_df = df.loc[(df[col_name] > lower_threshold) & (df[col_name] < upper_threshold)]\n",
    "    print(f'There were {start_len - len(new_df)} outliers removed from {col_name}')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:31.379798Z",
     "start_time": "2020-10-06T01:56:31.367676Z"
    }
   },
   "outputs": [],
   "source": [
    "df = iqr_outlier_rem(df, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:56:37.405594Z",
     "start_time": "2020-10-06T01:56:37.393748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The dataset now represents clients between the ages of 17 and 69 with a specific job status, marital status and education level. \n",
    "\n",
    "After the dropping of unknown values (from 3 columns) and outlier removal our dataset represents over 94% of the original dataset.\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Term Deposits By Job, Education & Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:15.415273Z",
     "start_time": "2020-10-06T00:51:14.413028Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "\n",
    "ax1 = sns.countplot(x='term_deposit',data=df)\n",
    "ax1.set(xlabel='Subscribed Term Deposit', ylabel='Count', title='Term Deposit')\n",
    "for p in ax1.patches:\n",
    "        ax1.annotate('{:.2f}%'.format((p.get_height()/df.shape[0])*100), (p.get_x()+0.3, p.get_height()))\n",
    "\n",
    "ax2 = df.groupby(['job', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax2.set(xlabel='Subscribed Term Deposit', ylabel='Job Count', title='Term Deposit X Job Type')\n",
    "for i in ax2.patches:\n",
    "    ax2.text(i.get_x()+0.05, i.get_height()+20,str(i.get_height()))\n",
    "\n",
    "ax3 = df.groupby(['education', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax3.set(xlabel='Subscribed Term Deposit', ylabel='Education Count', title='Term Deposit X Education Completed')\n",
    "for i in ax3.patches:\n",
    "    ax3.text(i.get_x()+0.05, i.get_height()+20,str(i.get_height()))\n",
    "\n",
    "ax4 = df.groupby(['marital', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax4.set(xlabel='Subscribed Term Deposit', ylabel='Marital Status Count', title='Term Deposit X Marital Status')\n",
    "for i in ax4.patches:\n",
    "    ax4.text(i.get_x()+0.05, i.get_height()+20,str(i.get_height()))\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Observations\n",
    "* The data is unbalanced with just under 11 percent of clients subscribing for a term deposit.\n",
    "* Some client jobs hold a closer no/yes ratio regarding term deposits. The four jobs with the largest variation are: admin, blue-collar, services and technician.  \n",
    "* The gap between no and yes variables appears to grow the more education a client has completed. Professional course and basic 6 year are the exception. \n",
    "* The majority of the dataset is represented by married couples with the greatest no/yes ratio existing in the \"divorced\" category.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Last Contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:16.166699Z",
     "start_time": "2020-10-06T00:51:15.417534Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,20))\n",
    "\n",
    "ax1 = df.groupby(['month', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax1.set(xlabel='Month', ylabel='Term Deposit Count', title='Term Deposit X Contact Month')\n",
    "for i in ax1.patches:\n",
    "    ax1.text(i.get_x()+0.05, i.get_height()+20,str(i.get_height()))\n",
    "\n",
    "ax2 = df.groupby(['day_of_week', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax2.set(xlabel='Day', ylabel='Term Deposit Count', title='Term Deposit X Contact Day of Week')\n",
    "for i in ax2.patches:\n",
    "    ax2.text(i.get_x()+0.05, i.get_height()+20,str(i.get_height()))\n",
    "\n",
    "ax3 = df.groupby(['contact', 'term_deposit']).size().unstack().plot(kind='bar', stacked=False,figsize=(6,5))\n",
    "ax3.set(xlabel='Contact Type', ylabel='Term Deposit Count', title='Term Deposit X Contact Type')\n",
    "for i in ax3.patches:\n",
    "    ax3.text(i.get_x()+0.05, i.get_height()+20,str(i.get_height()))\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.5)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Observations\n",
    "* There is a wide distribution of data when considering term deposits per month. The months with the most even distribution of yes/no are March, September, October and December.\n",
    "* There is no distinguishable difference in term deposits per day of the week. \n",
    "* The data illustrates higher odds of a subscriber term deposit when clients are reached via cell phone versus telephone. This may be due to changes in technology as less consumers maintain an active land line phone at home. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Other Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The dataset will be separated in order to show features that are representative of a \"yes\" in our target variable.\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:16.177292Z",
     "start_time": "2020-10-06T00:51:16.168556Z"
    }
   },
   "outputs": [],
   "source": [
    "yesdf = df[df['term_deposit'] == 'yes']\n",
    "nodf = df[df['term_deposit'] == 'no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:16.610896Z",
     "start_time": "2020-10-06T00:51:16.178528Z"
    }
   },
   "outputs": [],
   "source": [
    "# consider making two dataframes df1 for yes target and df2 for no target\n",
    "# then plotting\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(221)\n",
    "sns.scatterplot(yesdf.campaign, yesdf.term_deposit)\n",
    "plt.title('Campaign X Subscribed Term Deposits')\n",
    "plt.subplot(222)\n",
    "sns.scatterplot(yesdf.pdays, yesdf.term_deposit)\n",
    "plt.title('Days Since Last Contact X Subscribed Term Deposits')\n",
    "plt.subplot(223)\n",
    "sns.scatterplot(yesdf.previous, yesdf.term_deposit)\n",
    "plt.title('Client Contacts Performed X Subscribed Term Deposits')\n",
    "plt.subplot(224)\n",
    "sns.scatterplot(yesdf.poutcome, yesdf.term_deposit)\n",
    "plt.title('Previous Campaign Outcome X Subscribed Term Deposits')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Social & Economic Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.094201Z",
     "start_time": "2020-10-06T00:51:16.613052Z"
    }
   },
   "outputs": [],
   "source": [
    "# consider making two dataframes df1 for yes target and df2 for no target\n",
    "# then plotting\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(321)\n",
    "sns.scatterplot(yesdf['emp.var.rate'], yesdf.term_deposit)\n",
    "plt.title('Quarterly Employment Variation Rate X Subscribed Term Deposits')\n",
    "\n",
    "\n",
    "plt.subplot(322)\n",
    "sns.scatterplot(yesdf['cons.price.idx'], yesdf.term_deposit)\n",
    "plt.title('Consumer Price Index (Month) X Subscribed Term Deposits')\n",
    "\n",
    "\n",
    "plt.subplot(323)\n",
    "sns.scatterplot(yesdf['cons.conf.idx'], yesdf.term_deposit)\n",
    "plt.title('Consumer Confidence Index (Month) X Subscribed Term Deposits')\n",
    "\n",
    "\n",
    "plt.subplot(324)\n",
    "sns.scatterplot(yesdf.euribor3m, yesdf.term_deposit)\n",
    "plt.title('3 Mo. Euribor3m Rate (Daily) X Subscribed Term Deposits')\n",
    "\n",
    "plt.subplot(325)\n",
    "sns.scatterplot(yesdf['nr.employed'], yesdf.term_deposit)\n",
    "plt.title('Employee # Indicator (Quarterly) X Subscribed Term Deposits')\n",
    "\n",
    "plt.subplots_adjust(hspace=0.35)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notable Data Columns / Feature Conversions \n",
    "* Education - variables will be converted to numerical\n",
    "* Duration - a duration of zero directly ties to the target 'no' (remove before modeling)\n",
    "* Pdays - a value of 999 means the customer has not been contacted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.121442Z",
     "start_time": "2020-10-06T00:51:17.096450Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['education'].replace({'illiterate': 0, \n",
    "                         'basic.4y': 4, 'basic.6y': 6, \n",
    "                         'basic.9y': 9, 'high.school': 12, \n",
    "                         'professional.course': 14, \n",
    "                         'university.degree': 16}, inplace=True)\n",
    "\n",
    "# df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.124926Z",
     "start_time": "2020-10-06T00:51:17.123080Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.replace({'job': {'unknown':'that'}, \n",
    "#             'marital': {'unknown':'that'}, \n",
    "#             'education': {'unknown':'that'}, \n",
    "#             'default': {'unknown':'that'}, \n",
    "#             'housing': {'unknown':'that'},\n",
    "#             'loan': {'unknown':'that'}}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.140179Z",
     "start_time": "2020-10-06T00:51:17.130453Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop duration per dataset guidelines / drop columns with negative values\n",
    "df = df.drop(['duration', 'emp.var.rate', 'cons.conf.idx'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.147018Z",
     "start_time": "2020-10-06T00:51:17.143487Z"
    }
   },
   "outputs": [],
   "source": [
    "# cleaning column names\n",
    "subs = [(' ', '_'),('.0',''),('.','')]\n",
    "\n",
    "def col_formatting(col):\n",
    "    for old, new in subs:\n",
    "        col = col.replace(old,new)\n",
    "    return col\n",
    "\n",
    "df.columns = [col_formatting(col) for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.150637Z",
     "start_time": "2020-10-06T00:51:17.148673Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.621465Z",
     "start_time": "2020-10-06T00:51:17.152061Z"
    }
   },
   "outputs": [],
   "source": [
    "corr = df.corr() # analyzing correlation\n",
    "# corr\n",
    "fig, ax = plt.subplots(figsize=(18,26))\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "sns.heatmap(corr, mask=mask, square=True, annot=True, cmap=\"YlGnBu\")\n",
    "#xticklabels=labels, yticklabels=labels)\n",
    "#plt.xticks(rotation=-45, fontsize=16)\n",
    "ax.patch.set_edgecolor('black')  \n",
    "ax.patch.set_linewidth('1')\n",
    "ax.set_title(\"Correlation & Heat Map\", fontsize=15, fontfamily=\"serif\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.631000Z",
     "start_time": "2020-10-06T00:51:17.623976Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping feature to address multicollinearity \n",
    "df = df.drop(['euribor3m'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Features / One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.639205Z",
     "start_time": "2020-10-06T00:51:17.632420Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catfeats = df.select_dtypes('object').columns # selecting the numerical columns for observation\n",
    "catfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.677360Z",
     "start_time": "2020-10-06T00:51:17.640543Z"
    }
   },
   "outputs": [],
   "source": [
    "# One Hot Encode\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting Datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.711922Z",
     "start_time": "2020-10-06T00:51:17.678926Z"
    }
   },
   "outputs": [],
   "source": [
    "# changing uint8 data types back to categorical variables \n",
    "for cat_cols in df.iloc[:,7:].columns:\n",
    "         df[cat_cols] = df[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.819825Z",
     "start_time": "2020-10-06T00:51:17.713657Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test/Train Split / Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.825271Z",
     "start_time": "2020-10-06T00:51:17.821246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "y = df['term_deposit_yes']\n",
    "X = df.drop(['term_deposit_yes'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.904593Z",
     "start_time": "2020-10-06T00:51:17.826961Z"
    }
   },
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "scaler = StandardScaler() # transform \"X\" features\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.921863Z",
     "start_time": "2020-10-06T00:51:17.906216Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test/Train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.926009Z",
     "start_time": "2020-10-06T00:51:17.923630Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# # observing time lapse - running classifiers\n",
    "\n",
    "# # logistic regression classifier\n",
    "# # liblinear supports l2 regularization\n",
    "# lr = LogisticRegression(penalty='l2', solver='liblinear') \n",
    "\n",
    "# # Fit the model\n",
    "# fit = lr.fit(X_train, y_train)\n",
    "\n",
    "# pred_y = lr.predict(X_test) \n",
    "\n",
    "# lrs = round(lr.score(X_test, y_test)*100,2) # format accuracy score\n",
    "# print('\\nAccuracy Percentage:', lrs)\n",
    "\n",
    "\n",
    "# print('\\nActual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.930504Z",
     "start_time": "2020-10-06T00:51:17.927818Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# from catboost import CatBoostClassifier # Import library\n",
    "# catmodel = CatBoostClassifier(\n",
    "#     custom_loss=['Accuracy'], # Metric to use in training\n",
    "#     random_seed=0, # Consistent with other random seeds\n",
    "#     logging_level='Silent' # We already have the time function to show time elapsed\n",
    "# )\n",
    "# catmodel.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=(X_test, y_test),\n",
    "#     plot=False\n",
    "# ); #fit model\n",
    "\n",
    "# catscore = round(catmodel.score(X_test, y_test) * 100, 2) #round score \n",
    "# print('\\nAccuracy Percentage:', catscore)\n",
    "\n",
    "\n",
    "# pred_y_cat = catmodel.predict(X_test)\n",
    "# print('\\nActual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y_cat, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.935121Z",
     "start_time": "2020-10-06T00:51:17.932588Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_train, y_train) #fit model\n",
    "\n",
    "# knn_score = round(knn.score(X_test, y_test) * 100, 2) #round score\n",
    "# print('\\nAccuracy Percentage:', knn_score)\n",
    "\n",
    "# pred_y_knn = knn.predict(X_test) \n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') # Confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y_knn, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_knn)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.939694Z",
     "start_time": "2020-10-06T00:51:17.937039Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# # Linear SVC/SupportVectorMachine \n",
    "# linear_svc = LinearSVC()\n",
    "# linear_svc.fit(X_train, y_train)\n",
    "# linear_svc_score = round(linear_svc.score(X_test, y_test) * 100, 2) #round score\n",
    "# print('\\nAccuracy Percentage:', linear_svc_score)\n",
    "\n",
    "\n",
    "# pred_y_svc = linear_svc.predict(X_test) \n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y_svc, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.943419Z",
     "start_time": "2020-10-06T00:51:17.941375Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# clf = GaussianNB() #gaissian naive bayes\n",
    "# clf.fit(X_train, y_train) #fit the model\n",
    "\n",
    "# clf_score = round(clf.score(X_test, y_test) * 100, 2)\n",
    "# print(\"Accuracy Percentage: \", clf_score)\n",
    "\n",
    "# pred_y_clf = clf.predict(X_test) #y predicted\n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y_clf, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_clf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.947745Z",
     "start_time": "2020-10-06T00:51:17.945260Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# decision_tree = DecisionTreeClassifier()# Decision Tree \n",
    "# decision_tree.fit(X_train, y_train) #fit the model\n",
    "# decision_tree_score = round(decision_tree.score(X_test, y_test) * 100, 2) #round the result\n",
    "# print(\"Accuracy Percentage: \", decision_tree_score)\n",
    "\n",
    "# pred_y_decision_tree = decision_tree.predict(X_test) \n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y_decision_tree, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.951956Z",
     "start_time": "2020-10-06T00:51:17.949435Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# random_forest = RandomForestClassifier(n_estimators=100) # random forest \n",
    "# random_forest.fit(X_train, y_train) #fit the model\n",
    "# random_forest_score = round(random_forest.score(X_test, y_test) * 100, 2) #round the result\n",
    "# print(\"Accuracy Percentage: \", random_forest_score)\n",
    "\n",
    "# pred_y_random_forest = random_forest.predict(X_test) \n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab( y_test, pred_y_random_forest, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.956077Z",
     "start_time": "2020-10-06T00:51:17.953803Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "\n",
    "# clf_gb = GradientBoostingClassifier(n_estimators=100, \n",
    "#                                  max_depth=1, \n",
    "#                                  random_state=0)\n",
    "# clf_gb.fit(X_train, y_train)\n",
    "# clf_gb_score = round(clf_gb.score(X_test, y_test) * 100, 2)\n",
    "# print(\"Accuracy Percentage: \", clf_gb_score)\n",
    "\n",
    "\n",
    "# pred_y_clf_gb = clf_gb.predict(X_test) \n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab(y_test, pred_y_clf_gb, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_clf_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.959882Z",
     "start_time": "2020-10-06T00:51:17.957729Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# bdt = AdaBoostClassifier(DecisionTreeClassifier(max_depth=8), \n",
    "#                          algorithm=\"SAMME\",\n",
    "#                          n_estimators=200)\n",
    "# bdt.fit(X_train, y_train) #fit model\n",
    "# bdt_score = round(bdt.score(X_test, y_test) * 100, 2) #round score\n",
    "# print(\"Accuracy Percentage: \", bdt_score) #4:45\n",
    "\n",
    "\n",
    "# pred_y_bdt = bdt.predict(X_test) \n",
    "\n",
    "# print('\\n Actual vs. Predicted \\n') #confusion matrix\n",
    "# print(pd.crosstab( y_test, pred_y_bdt, rownames=['True'], colnames=['Predicted'], margins=True))\n",
    "\n",
    "# print('\\n\\n\\n', classification_report(y_test, pred_y_bdt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.964142Z",
     "start_time": "2020-10-06T00:51:17.961662Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # results dataframe\n",
    "# models = pd.DataFrame({\n",
    "#     'Model': ['Logistic Regression',\n",
    "#               'KNN', \n",
    "#               'Random Forest', \n",
    "#               'Gaussian Naive Bayes',\n",
    "#               'Linear SVC (SVM)', \n",
    "#               'Decision Tree', \n",
    "#               'AdaBoostClassifier', \n",
    "#               'GradientBoostingClassifier',\n",
    "#               'CatBoost',\n",
    "#              ],\n",
    "#     'Score': [lrs, \n",
    "#               knn_score, \n",
    "#               random_forest_score, \n",
    "#               clf_score,\n",
    "#               linear_svc_score, \n",
    "#               decision_tree_score,\n",
    "#               bdt_score, \n",
    "#               clf_gb_score, \n",
    "#               catscore,\n",
    "#              ]})\n",
    "\n",
    "# models.sort_values(by='Score', ascending=False) #sorting by score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "It looks like Catboost is the most accurate with Logistic Regression coming in incredibly close at second. Gradient Boosting Classifier comes in at third place with Support Vector Machine coming at a close 4th place. The least accurate is \n",
    "Gaussian Naive Bayes coming in 25 points lower than Catboost.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Pipeline with GridSearchCV\n",
    "Let's see if we can improve our results at all using GridSearch. Gridsearch will run and compare each combination of parameters in a set of parameters that we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.967903Z",
     "start_time": "2020-10-06T00:51:17.965902Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_pipe = df['term_deposit_yes']\n",
    "# X_pipe = df.drop(['term_deposit_yes'], axis=1) \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_pipe, y_pipe, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.972394Z",
     "start_time": "2020-10-06T00:51:17.969654Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.decomposition import PCA \n",
    "\n",
    "# # Creating a pipeline\n",
    "# rf_pipe = Pipeline([('scl', StandardScaler()),\n",
    "#                  ('pca', PCA(n_components=5)), #arbitrary number\n",
    "#                  ('clf', RandomForestClassifier(random_state = 0))])\n",
    "\n",
    "\n",
    "# # Set grid search params\n",
    "# rf_grid_param = [ \n",
    "#   {'clf__n_estimators': [100], \n",
    "#    'clf__max_features': ['auto', 'sqrt'],\n",
    "#    'clf__max_depth': [None],  \n",
    "#    'clf__min_samples_leaf':[1, 2],   \n",
    "#    'clf__min_samples_split':[2, 10],\n",
    "#   }\n",
    "# ]\n",
    "\n",
    "# # Construct grid search\n",
    "# rf_gridsearch = GridSearchCV(estimator=rf_pipe,\n",
    "#             param_grid=rf_grid_param,\n",
    "#             scoring='accuracy',\n",
    "#             cv=3, verbose=2)\n",
    "\n",
    "# # Fit using grid search\n",
    "# rf_gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.976005Z",
     "start_time": "2020-10-06T00:51:17.974113Z"
    }
   },
   "outputs": [],
   "source": [
    "# # print best parameters\n",
    "# print('\\nBest params:\\n', rf_gridsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.979615Z",
     "start_time": "2020-10-06T00:51:17.977686Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "# #applying best parameters to model\n",
    "# random_forest = RandomForestClassifier(n_estimators=100, max_features='sqrt', min_samples_leaf= 2, min_samples_split= 10) # random forest \n",
    "# random_forest.fit(X_train, y_train) #fit the model\n",
    "# random_forest_score = round(random_forest.score(X_test, y_test) * 100, 2) #round the result\n",
    "# print(\"Accuracy Percentage: \", random_forest_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Gridsearch CV did not raise the accuracy of the model. Let's see if we can improve the accuracy in some of our other models by addressing our class imbalance problem.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.983637Z",
     "start_time": "2020-10-06T00:51:17.981386Z"
    }
   },
   "outputs": [],
   "source": [
    "# # visualizing churn\n",
    "# plt.bar(['No Term Deposit', 'Term Deposit'], df.term_deposit_yes.value_counts().values, facecolor = 'blue',  linewidth=0.5)\n",
    "# plt.title('Target Variable (Subscribed Term Deposits)', fontsize=16)\n",
    "# plt.xlabel('Classes')\n",
    "# plt.ylabel('Total Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-05T22:17:31.625260Z",
     "start_time": "2020-10-05T22:17:31.621146Z"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The graph above highlights that there is a a pretty high level of imbalance. We can remedy this using SMOTE.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE (Synthetic Minority Over-sampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.987190Z",
     "start_time": "2020-10-06T00:51:17.985278Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Separate target and features\n",
    "# y = df['term_deposit_yes']\n",
    "# X = df.drop(['term_deposit_yes'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.990843Z",
     "start_time": "2020-10-06T00:51:17.988944Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_scaled = scaler.fit_transform(X) #scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.994776Z",
     "start_time": "2020-10-06T00:51:17.992627Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0) #test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:17.998759Z",
     "start_time": "2020-10-06T00:51:17.996498Z"
    }
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE #import smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.002558Z",
     "start_time": "2020-10-06T00:51:18.000586Z"
    }
   },
   "outputs": [],
   "source": [
    "# smote = SMOTE(random_state=0) #random state 0 for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.006355Z",
     "start_time": "2020-10-06T00:51:18.004201Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# X_res, y_res = smote.fit_resample(X_train, y_train) #fitting smote to our train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.010295Z",
     "start_time": "2020-10-06T00:51:18.008057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Updated bar graph to display amount of failed vs. successful campaigns post-SMOTE\n",
    "# plt.bar(['Customer Retention', 'Customer Churn'], [sum(y_res), len(y_res)-sum(y_res)], facecolor = 'green',  linewidth=0.5)\n",
    "# plt.title('Post-SMOTE Target Variable (Success)\\n', fontsize=16)\n",
    "# plt.xlabel('Classes')\n",
    "# plt.ylabel('Number of Campaigns')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "It looks like our classes are balanced now. Let's proceed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.014498Z",
     "start_time": "2020-10-06T00:51:18.012091Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# #just a few classifiers for sake of time\n",
    "# l_r = LogisticRegression(penalty='l2', solver='liblinear')\n",
    "# randomforest = RandomForestClassifier(n_estimators=100)\n",
    "# cat_model = CatBoostClassifier(\n",
    "#     custom_loss=['Accuracy'], # metric to use in training\n",
    "#     random_seed=0, # consistent with other random seeds\n",
    "#     logging_level='Silent' # time function will show time lapse\n",
    "# )\n",
    "# decisiontree = DecisionTreeClassifier()\n",
    "\n",
    "# classifiers = [l_r, randomforest, cat_model, decisiontree] # list of classifiers\n",
    "# classifiers_names = ['Logistic Regression', 'Random Forest','Cat Model', 'Decision Tree'] # respective names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.018808Z",
     "start_time": "2020-10-06T00:51:18.016569Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# # iterating through a list of classifiers and appending their accuracy levels to a list of scores\n",
    "# scores = []\n",
    "# for i in range(len(classifiers)):\n",
    "#     classifiers[i].fit(X_res, y_res)\n",
    "#     scores.append(round(classifiers[i].score(X_test, y_test), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.022557Z",
     "start_time": "2020-10-06T00:51:18.020569Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # dataframe to compare results\n",
    "# dfsmote = pd.DataFrame({'Model': classifiers_names, 'Score': scores})\n",
    "\n",
    "# dfsmote.sort_values(by='Score', ascending=False) # sorting models by score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "The models performed worse than they did initially. SMOTE wasn't particularly worth it as it did not significantly impact model performance. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance of Top Classifiers\n",
    "\n",
    "Now that we know which classifiers have the most accuracy with our data, let's compare which features were the most important in the top three models: Catboost, Logistic Regression, and Gradient Boosting Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.026573Z",
     "start_time": "2020-10-06T00:51:18.024364Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Feature Importance\n",
    "# cat_feature = pd.DataFrame({'Importance': catmodel.feature_importances_, 'Column': X.columns}) # new dataframe\n",
    "# cat_feature = cat_feature.sort_values(by='Importance', ascending=False) # results highest to lowest\n",
    "# print('Catboost Top 25 Features')\n",
    "# cat_feature[:25] # top 25 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.030293Z",
     "start_time": "2020-10-06T00:51:18.028294Z"
    }
   },
   "outputs": [],
   "source": [
    "# cat_feature = cat_feature[:25] # top 25 features\n",
    "# cat_feature.plot(kind='barh', x='Column', y='Importance', figsize=(20, 10), cmap = 'coolwarm')\n",
    "# plt.title('Catboost Feature Importance \\n', fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.034486Z",
     "start_time": "2020-10-06T00:51:18.032152Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Feature Importance\n",
    "# rf_feature = pd.DataFrame({'Importance': random_forest.feature_importances_, 'Column': X.columns}) #create new dataframe\n",
    "# rf_feature = rf_feature.sort_values(by='Importance', ascending=False) #display results highest to lowest\n",
    "# print('Random Forest Top 25 Features')\n",
    "# rf_feature[:25] #top 25 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.038589Z",
     "start_time": "2020-10-06T00:51:18.036089Z"
    }
   },
   "outputs": [],
   "source": [
    "# rf_feature = rf_feature[:25] #top 25 features\n",
    "# rf_feature.plot(kind='barh', x='Column', y='Importance', figsize=(20, 10), cmap= 'ocean')\n",
    "# plt.title('Random Forest Feature Importance \\n', fontsize=16)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.043224Z",
     "start_time": "2020-10-06T00:51:18.040778Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Creating lists / top 25 features in each classifier \n",
    "# cat = cat_feature.Column.unique() \n",
    "# rf = rf_feature.Column.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:18.046958Z",
     "start_time": "2020-10-06T00:51:18.044867Z"
    }
   },
   "outputs": [],
   "source": [
    "# set(cat) & set(rf) # items appearing in both lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "There are 23 total items that appear in both classifier feature lists. \n",
    "\n",
    "The most important features in both lists are:\n",
    "* **Number of employees | quarterly indicator (nremployed)**\n",
    "* **Consumer Price Index | monthly indicator (conspriceidx)**\n",
    "* **Age**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:51:48.648118Z",
     "start_time": "2020-10-06T00:51:48.623772Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yesdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:20:40.558054Z",
     "start_time": "2020-10-06T01:20:40.353213Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Subscriber Term Deposits X Number of Employees (Quarterly)')\n",
    "print(yesdf['nr.employed'].value_counts())\n",
    "yesdf['nr.employed'].hist(figsize = (8,8), color = \"blue\"); #let's make a histogram to compare\n",
    "plt.title('Subscriber Term Deposits X Number of Employees (Quarterly)', fontdict={'fontsize': 16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:19:42.155392Z",
     "start_time": "2020-10-06T01:19:41.952035Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Subscriber Term Deposits X Consumer Price Index (Monthly)')\n",
    "print(yesdf['cons.price.idx'].value_counts())\n",
    "yesdf['cons.price.idx'].hist(figsize = (8,8), color = \"red\"); #let's make a histogram to compare\n",
    "plt.title('Subscriber Term Deposits X Consumer Price Index (Monthly)', fontdict={'fontsize': 16});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T01:17:27.227098Z",
     "start_time": "2020-10-06T01:17:27.030148Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Age')\n",
    "print(yesdf['age'].value_counts())\n",
    "yesdf['age'].hist(figsize = (8,8), color = \"green\"); #let's make a histogram to compare\n",
    "plt.title('Subscriber Term Deposits X Age', fontdict={'fontsize': 16});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion Business Insights and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset and given business insights relay specifically to a client base that cites their specific job type, marital status and education level. Additionally, the models and features reflect a client that is between 17-69 years of age. \n",
    "\n",
    "**Subscriber term deposits are highest when the number of quarterly employees are at least 5099 but not over 5228. In addition, consumer price index should be between 92.89 and 93.08. Lastly, clients between the ages of 30-40 are the most likely to subscribe term deposits.**\n",
    "\n",
    "Future work: In order to more accurately define the boundaries of our features it is important to understand what customs and cultural influences are tied to this dataset (Portuguese banking info). For example: knowing the average level of education, the geographic locations of client residences and information on financial markets in this region may alter the way we perceive each of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
